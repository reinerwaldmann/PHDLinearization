Лабораторный журнал

14.11.2014

Пытаемся оценить  параметры обычного диода  I=Is*(math.exp(Vd/(FT*N)) -1)


Обнаружилась проблема - Ofiura_Estimation некорректно работает со случаем, когда модель однооткликовая.
B5 получается двухразмерная [[]] и соотв. размеры матриц не подходят
Вылечено вот так
if hasattr(B5, 'A1'):
            B5=B5.A1
Решение костыльное абсолютно. Проблема лежит в преобразовании типов numpy. Что-то к чему-то сильно не тому преобразовывается


Хуже того - не хочет оценивать в случае, если N<1, да и вообще часто пробшемы с оценкой
Возможно дело в том, что параметры, находящиеся под экспонентой, плохо оцениваются..почему-то

Коэффициент неидеальности диода N лежит в пределах от 1 до 2, но чем ближе к 2, тем хуже оценивается (ситуация несколько исправляется подгонкой начального значения)
Регулярно отваливается из-за переполнения буфера

А ещё любит отваливаться по сингулярной матрице G

Пробуем  тестить априорное планирование. Регулярно отваливается по сингулярности

unoptimized-optimized: 3.10836801079e-102 6.05820816833e-113



16.11.2014
Увеличил в методе Гаусса-Ньютона количество допустимых итераций со 100 до 500. На 126 итерации при
    Ve=np.asmatrix( [0.1]   )
    xstart=[0.01]
    xend=[2]
    btrue=[1.238e-14, 1.8]
    binit=[1e-10,1.1]

Сосчитал
Для нормальной оценки
    N=30

Sk: 3.60041044444
('Среднее логарифма правдоподобия Дисперсия лп Сигма лп Среднее остатков Дисп. остатков Сигма остатков\n',
 (1.2415208429083677, 2.4193403536561289, 1.5554228857954124), (0.044810052565276939, 0.1141343315902025, 0.33783772967240133))
и коэфф
[  1.23866730e-14   1.80002242e+00]

Для оценки по априорному плану
    N=20
130 итераций (хуже)
Sk: 1.48041222804 (лучше)
('Среднее логарифма правдоподобия Дисперсия лп Сигма лп Среднее остатков Дисп. остатков Сигма остатков\n',
 (0.8224512378014015, 1.0960686711485694, 1.0469329831219234), (-0.11127551749409992, 0.061638370608546399, 0.24827076067984002))
и коэфф
[  1.23781918e-14   1.79999393e+00]

Что говорит о том, что в принципе априорный план лишь чуть лучше, да и то не по всем показателям.
Помним, однако, что число точек при априорной оценке на 10 меньше. Пробуем для тех же данных увеличить его до 30
Внимание! хотя в общем это и неверно, но в данном случае для нормального исследования действительно 30 (реально 31) точек в плане. Обычно их гораздо больше
Рассматривая результаты априорного планирования, мы закономерно видим, что точки начинают более равномерно распределяться по экспоненте, что позволяет лучше оценить кривизну функции.
Но случайные экспериментальные планы не сильно уступают оптимизированным.
Эксперимент с 30 точками вылетел из-за ошибки переполнения, затем выдал вот такие результаты
Sk: 4.54670794194
Iteration 143 mu=2.0 delta=[  1.88113508e-21   8.30752240e-09] deltamu=[  3.76227015e-21   1.66150448e-08] resb=[  1.23860357e-14   1.80002047e+00]
[  1.23860357e-14   1.80002047e+00]
('Среднее логарифма правдоподобия Дисперсия лп Сигма лп Среднее остатков Дисп. остатков Сигма остатков\n',
(1.6238242649797059, 3.7591544757997561, 1.9388539078021727), (-0.047102022475391733, 0.14933833087683357, 0.3864431793638407))

Что, собственно говоря, даже несколько хуже, нежели полученное при нормальном исследовании



***
Важный момент - перестроить функции на работу с функцией measure, то есть той, что выдаёт результат измеренйи с погрешностью, но с btrue. Переделать надо:
 - o_p, makeMeasAccToPlan(func, expplan:list, b:list, c:dict, Ve=[], n=1, outfilename="", listOfOutvars=None) и ему подобные
 - o_sp, использующие вышеприведённые функции

Помозговать над улучшениеям критериев окончания последовательного плана
Написать штуку, которая бы по qualität - показателям выбирала наилучшую оценку, в соответствии с балльной системой (за  каждый показатель - по баллу)
и выводила бы красивые графики сравнения

В Research mode  -  графики сравнения  и проч.
В Enterprise mode  - лучшую оценку и qualität
********************************
Критичные вопросы об оценке качества
1. Как правдивее всего сравнить методы? по собственным выборкам эксп. данных или же по одной выборке, не являющейся обучающей
 ни для одного из методов, но такой, чтобы все точки были в рамках обучающих методов?

2. Если в каждой точке производить измерения некоторое число раз (интресно, какое оптимально?), затем оные данные усреднять,
как изменится реальная ковариационная матрица Ve, с которой мы работаем?

3. При проведении в каждой точке нескольких измерений появляются вот какие возможности:
    +Можно оценить, нормально ли распределение
    +Можно оценить ковариационную матрицу (собственно, мы всё время полагали, что она уже оценена и именно таким образом, но это сделано
    единственный раз и мы полагаем, что для всех такого рода изделий и измерений она одинакова)
    +И можно серьёзным образом уточнить наши измерения.
---------------------

Методы уточнения результатов оценки коэффициентов
1. Для последовательного планирования - ограничение по полке среднего логарифма функции правдоподобия
2. Для всех - прогон нескольких методов и выбор лучшего по среднему логарифма функции правдоподобия
3. Использование полученного для одного изделия последовательного плана как априорного и для изделия иного типа. Для схожих изделий с разными значениями
параметров можно данный план использовать как затравку для априорного
4. Для некоторых моделей есть точки, вызывающие переполнение. Их должно не вносить в план а итеративно перемещать, пока оне не будет нормально считаться.
5. Подгонка настроечных параметров функции gnux
6. Метод выбора начального приближения
Практика использования оценочных методов показывает, что они часто бывают весьма чувствительны к начальным показателям. Применительно к моделям полупроводниковых приборов в ходе экспериментов была обнаружена также часто случающаяся проблема возникновения ошибки переполнения при вычислениях - даже если при истинных или близких к истинным параметрам модель вычисляется нормально, при слишком далёких от истинных начальных значениях может произойти вычислительная ошибка переполнения, что приведёт к некорректным результатам, и, как следствие, неверной оценке или вообще к невозможности произвести оценку.
Для решения данной проблемы разработан метод подбора оптимального начального приближения вектора коэффициентов. Его идея
заключается в том, что, при исследовании нового типа изделий определяются границы наиболее вероятного значения вектора коэффициентов.
 Затем метод оценки прогоняется несколько раз, каждый раз со случайным начальным вектором из этого диапазона, выбираемым по равномерному распределению.
 Затем из полученных оценок выбирается наилучшая в соответствии с качественными показателями {ссылка}. После того, как по данному типу изделий набирается
 некоторая статистика, то начальное значение выбирается уже не по равномерному распределению, а по нормальному распределению со средним, равным среднему
 значению вектора коэффициентов по набранной статистике и доверительным интервалом, равным заданному диапазону.

Подход себя полностью оправдал


7. Применение инструментов с повышенной точностью вычисления
8.


Проверить многоразовые измерения в том случае, если дисперсия высока.
Вообщеспособ пахнет бредом - проще уж несколько раз в точке померить, но при этом задача технически сводится к имеющейся, лишь дисперсия меняется



Пока не очень понятно, а как extrastart, требующий range для b, совместить с sequencePlan, его не требующий, зато требующиё binit
GKNU в SP заменяется:
 +в дубовом случае на extrastart впрямую, что требует в ntries раз больше времени
 +в менее дубовом binit=середина диапазона, но тоже так себе
 +в ещё менее дубовом - сперва диапазон, а потом binit=b, собственно, сейчас вроде так.

Заключительно на 25Дек2014:
метод выбора нач. прибл. себя оправдал в классическом варианте, в SP не применён
многоразовые измерения могут дать выгоду по среднему ЛФП в 2 порядка
распределение остатков очень похоже на нормальное, теперь бы крутануть на последовательном плане, где точек побольше
и для приличия можно запостить анализатор вида распределения (проверялку на нормальность) и на нульсреднее, но в целом, скорее всего, всё ОК
Пора ваять отчёт в кошерном виде в латехе про диод с улучшениями


Написать методику формирования оптимизационной программы


Финальное разъяснение относительно теста на None:
if val is not None:
    # ...
is the Pythonic idiom for testing that a variable is not set to None.
This idiom has particular uses in the case of declaring keyword functions with default parameters.
 is tests identity in Python. Because there is one and only one instance of None present in a running Python script/program,
  is is the optimal test for this. As Johnsyweb points out, this is discussed in PEP 8 under "Programming Recommendations".

 И до кучи
 You use == when comparing values and is when comparing identities.


Я просто оставлю это здесь
http://www.livejournal.com/magazine/644533.html?xtor=EPR-1-%5BCampaign_2015_02_13%20_33_11_sending_10:12%5D-20150213-%5Bpost_10%5D-%5B11%5D

http://www.livejournal.com/magazine/447515.html






