Сосредотачиваемся на реализации алгоритма поэлементного выбора факторов. Потом уже можно наращивать степень полинома.

Как и всегда, при интерполяции особенно важны 2 задачи:
1. Выбор переменной
2. Сравнение длинной и короткой модели
3. Проверка итоговой адекватности модели

1-я задача
Может решаться двумя подходами
    - по гамма-критерию, который работает применительно к линейным моделям (сиречь определяет качество
    описания модели по степени наклона линии регрессии
    - по отношению правдоподобия. Проанализировав формулу, понимаем, что сравнивать модели
    можно лишь по максимизирующему компоненту функции правдоподобия (n,k-число эл. модели, Ve
    у всех моделей будет одинаковое.

2-я задача
    -по гамма же критерию и отношению Фишера
    -по критерию правдоподобия
    Сущность надо бы проверить, но с учётом LR=2(Ll-Ls) мы получаем, что сравнивать можно
    опять-таки максимизирующий компонент.

3-я задача
    -С учётом чуть более, чем напрочь неизвестного Ve, превращается в нетривиальную задачу.
    Потому что определить распределение ошибок ну какбы напрочь непонятно как.
    Разве если оценить Ve с помощью остатков, дальше проверить на нулевое среднее (выполнится стопудово)
    ии..сравнить ков. матрицу остатков и убедиться, что она равна оценке Ve, ибо считается практически
    так же. Реально оценить адекватность модели данным, вот так сферически в вакууме - невозможно,
    реально лишь сравнить разные модели. Потому задача толком бессмысленна. Потому метод
    "накручивать степень пока критерий не встанет на плато, или пока степень не доползёт эдак до 4-й"
    выглядит весьма и весьма неплохо.



    Пичальбида в том, что максимизирующий компонент в обеих задачах содержит матрицу Ve.
     Оценка коэффициентов может осуществляться и без неё, но вот насчёт сравнения по статистике хиквадрат -
     вряд ли. Ve оценивается через модель, но фишка в том, что непонятно, через какую
     (как вариант, можно оценить Ve через полную модель, в предположении, что полная модель явно
     содержит знач  имые переменные и, следственно, явно адекватнее сокращённых).
     Есть правда надежда, что и сравнение можно делать без Ve, так как формально Ve одинакова для
     любой модели.


-------------------------------------------------------------------
Теперь
1 берём данные, строим линейную регрессию, считаем правдоподобие (как минимум, максимизирующий компонент)
2 удаляем левые переменные, по принципу. Т. е. "отсеиваем лишнее"
3 строим регрессиию по оставшимся.
4 проверяем адекватность
Опция, но надо бы
1. Накидываем степень
то же самое


